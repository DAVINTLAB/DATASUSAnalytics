{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e13170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNIFICAR OS PARQUETS\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# Caminhos\n",
    "pasta_parquets = \"datasus/parquet\"\n",
    "saida_parquet = \"datasus/parquet_unificado/sih_rs.parquet\"\n",
    "\n",
    "# Colunas desejadas (extraídas do arquivo )\n",
    "colunas_desejadas = [\n",
    "     'ESPEC', 'N_AIH', 'IDENT', 'CEP', 'MUNIC_RES', 'NASC', 'SEXO', 'DI_INTER', 'DT_SAIDA',\n",
    "    'UTI_MES_TO', 'MARCA_UTI', 'UTI_INT_TO', 'DIAR_ACOM', 'QT_DIARIAS', 'PROC_SOLIC', 'PROC_REA', 'VAL_SH', 'VAL_SP', 'VAL_TOT',\n",
    "    'VAL_UTI',  'NATUREZA', 'CNES',  'NAT_JUR', 'GESTAO', 'IND_VDRL', 'IDADE', 'DIAG_PRINC', \n",
    "    'DIAG_SECUN', 'COBRANCA', 'MORTE',  'MUNIC_MOV', 'DIAS_PERM', 'NACIONAL', \n",
    "    'NUM_FILHOS', 'INSTRU', 'CID_NOTIF', 'CONTRACEP1', 'CONTRACEP2', 'GESTRICO', 'INSC_PN', 'CBOR',\n",
    "    'CNAER', 'VINCPREV', 'INFEHOSP', 'CID_ASSO', 'CID_MORTE', 'COMPLEX', 'RACA_COR', 'ETNIA',\n",
    "    'DIAGSEC1', 'DIAGSEC2', 'DIAGSEC3', 'DIAGSEC4', 'DIAGSEC5', 'DIAGSEC6', 'DIAGSEC7', 'DIAGSEC8', 'DIAGSEC9', \n",
    "    'TPDISEC1', 'TPDISEC2', 'TPDISEC3', 'TPDISEC4', 'TPDISEC5', 'TPDISEC6', 'TPDISEC7', 'TPDISEC8', 'TPDISEC9', 'COD_IDADE'\n",
    "\n",
    "]\n",
    "\n",
    "# Lista todos os arquivos .parquet na pasta\n",
    "arquivos = glob(os.path.join(pasta_parquets, \"*.parquet\"))\n",
    "\n",
    "# Lista para armazenar os DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Itera sobre os arquivos .parquet\n",
    "for arquivo in arquivos:\n",
    "    df = pd.read_parquet(arquivo)\n",
    "\n",
    "    # Adiciona colunas ausentes com NaN\n",
    "    for coluna in colunas_desejadas:\n",
    "        if coluna not in df.columns:\n",
    "            df[coluna] = pd.NA\n",
    "\n",
    "    # Mantém apenas as colunas desejadas \n",
    "    df = df[colunas_desejadas]\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatena todos os DataFrames\n",
    "df_final = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Cria a pasta de saída, se necessário\n",
    "os.makedirs(os.path.dirname(saida_parquet), exist_ok=True)\n",
    "\n",
    "# Salva o arquivo unificado\n",
    "df_final.to_parquet(saida_parquet, index=False)\n",
    "\n",
    "print(\" Arquivo sih_rs.parquet criado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5082e7c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cabf036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
